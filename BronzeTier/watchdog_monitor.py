"""
watchdog_monitor.py â€“ System Watchdog (Bronze â†’ Platinum)

Monitors the Orchestrator.py process and auto-restarts it if it crashes.
Also monitors disk space, memory, and vault health.

Run this INSTEAD of Orchestrator.py directly:
    python watchdog_monitor.py

It will start Orchestrator.py as a subprocess and keep it alive.

Error Category: SYSTEM (Orchestrator crash, disk full) â†’ auto-restart
"""

import json
import logging
import os
import shutil
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path

import sys
from dotenv import load_dotenv

# Ensure BronzeTier/ is in path and .env is loaded correctly
_BRONZE_DIR = Path(__file__).resolve().parent
if str(_BRONZE_DIR) not in sys.path:
    sys.path.insert(0, str(_BRONZE_DIR))
load_dotenv(dotenv_path=_BRONZE_DIR / ".env")

log = logging.getLogger("WatchdogMonitor")
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [WatchdogMonitor] %(levelname)s %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler("watchdog.log", encoding="utf-8"),
    ],
)

# â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VAULT_PATH          = Path(os.getenv("VAULT_PATH", "./Vault"))
ERROR_LOG_PATH      = Path(os.getenv("ERROR_LOG_PATH", "./logs/errors.jsonl"))
ORCHESTRATOR_SCRIPT = Path(__file__).parent / "Orchestrator.py"
MAX_RESTARTS        = int(os.getenv("WATCHDOG_MAX_RESTARTS", "10"))
RESTART_DELAY       = int(os.getenv("WATCHDOG_RESTART_DELAY", "15"))   # seconds
HEALTH_INTERVAL     = int(os.getenv("WATCHDOG_HEALTH_INTERVAL", "60")) # seconds
MIN_DISK_GB         = float(os.getenv("WATCHDOG_MIN_DISK_GB", "1.0"))  # alert if below


def _write_jsonl(path: Path, record: dict):
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("a", encoding="utf-8") as f:
        f.write(json.dumps(record, default=str) + "\n")


def _alert_vault(subject: str, body: str):
    """Write a critical alert .md into /Needs_Action so human sees it in Obsidian."""
    now = datetime.now()
    alert_dir = VAULT_PATH / "Needs_Action"
    alert_dir.mkdir(parents=True, exist_ok=True)
    alert_path = alert_dir / f"ALERT_SYSTEM_{now.strftime('%Y%m%d_%H%M%S')}.md"
    alert_path.write_text(
        f"""---
type: system_alert
subject: {subject}
created: {now.isoformat()}
priority: critical
---

# ðŸš¨ {subject}

{body}

*Auto-generated by WatchdogMonitor*
""",
        encoding="utf-8",
    )
    log.critical("Alert written to vault: %s", alert_path.name)


def check_disk_space() -> float:
    """Return free disk space in GB for the vault drive."""
    try:
        usage = shutil.disk_usage(str(VAULT_PATH))
        free_gb = usage.free / (1024 ** 3)
        return free_gb
    except Exception:
        return 999.0  # Can't check â€” don't block


def health_checks() -> dict:
    """Run system health checks. Returns dict with any warnings."""
    issues = {}

    # Disk space
    free_gb = check_disk_space()
    if free_gb < MIN_DISK_GB:
        issues["disk"] = f"LOW DISK SPACE: {free_gb:.2f} GB free (min {MIN_DISK_GB} GB)"

    # Vault exists
    if not VAULT_PATH.exists():
        issues["vault"] = f"Vault path missing: {VAULT_PATH}"

    # Needs_Action backlog
    needs_action = VAULT_PATH / "Needs_Action"
    if needs_action.exists():
        backlog = len(list(needs_action.glob("*.md")))
        if backlog > 50:
            issues["backlog"] = f"Needs_Action backlog is large: {backlog} files"

    return issues


class WatchdogMonitor:
    """
    Starts Orchestrator.py as a subprocess.
    If it exits (crash or error), restarts it automatically.
    Monitors disk, memory, and vault health in parallel.
    """

    def __init__(self):
        self._process: subprocess.Popen | None = None
        self._restart_count = 0
        self._start_time = datetime.now()

    def start_orchestrator(self) -> subprocess.Popen:
        """Launch Orchestrator.py as a subprocess."""
        log.info("Starting Orchestrator.py (restart #%d)...", self._restart_count)
        # Always run from BronzeTier/ so relative imports work correctly
        bronze_dir = Path(__file__).resolve().parent
        proc = subprocess.Popen(
            [sys.executable, str(ORCHESTRATOR_SCRIPT)],
            stdout=sys.stdout,
            stderr=sys.stderr,
            cwd=str(bronze_dir),
        )
        _write_jsonl(ERROR_LOG_PATH, {
            "timestamp": datetime.now().isoformat(),
            "category": "system",
            "component": "WatchdogMonitor",
            "message": f"Orchestrator started (PID={proc.pid}, restart #{self._restart_count})",
        })
        return proc

    def run(self):
        log.info("=" * 60)
        log.info("AI Employee Watchdog Monitor")
        log.info("Orchestrator: %s", ORCHESTRATOR_SCRIPT)
        log.info("Max restarts: %d | Restart delay: %ds", MAX_RESTARTS, RESTART_DELAY)
        log.info("=" * 60)

        self._process = self.start_orchestrator()
        last_health_check = time.time()

        while True:
            # â”€â”€ Health checks (every HEALTH_INTERVAL seconds) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if time.time() - last_health_check >= HEALTH_INTERVAL:
                issues = health_checks()
                for key, msg in issues.items():
                    log.warning("[HEALTH] %s: %s", key, msg)
                    _write_jsonl(ERROR_LOG_PATH, {
                        "timestamp": datetime.now().isoformat(),
                        "category": "system",
                        "component": f"WatchdogMonitor/{key}",
                        "message": msg,
                    })
                    _alert_vault(f"System Warning: {key}", msg)
                last_health_check = time.time()

            # â”€â”€ Check if orchestrator is still running â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            exit_code = self._process.poll()

            if exit_code is None:
                # Still running â€” all good
                time.sleep(5)
                continue

            # â”€â”€ Orchestrator exited â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            log.error(
                "Orchestrator exited with code %d (restart %d/%d)",
                exit_code, self._restart_count, MAX_RESTARTS,
            )
            _write_jsonl(ERROR_LOG_PATH, {
                "timestamp": datetime.now().isoformat(),
                "category": "system",
                "component": "WatchdogMonitor",
                "message": f"Orchestrator crashed (exit_code={exit_code})",
                "restart_count": self._restart_count,
            })

            if self._restart_count >= MAX_RESTARTS:
                msg = (
                    f"Orchestrator has crashed {self._restart_count} times. "
                    f"Watchdog giving up. Manual intervention required."
                )
                log.critical(msg)
                _alert_vault("CRITICAL: Orchestrator repeatedly crashing", msg)
                sys.exit(1)

            # â”€â”€ Wait before restart (exponential backoff up to 5 min) â”€â”€â”€â”€â”€â”€â”€
            delay = min(RESTART_DELAY * (2 ** min(self._restart_count, 5)), 300)
            log.info("Restarting in %ds...", delay)
            time.sleep(delay)

            self._restart_count += 1
            self._process = self.start_orchestrator()

    def stop(self):
        if self._process and self._process.poll() is None:
            log.info("Stopping Orchestrator (PID=%d)...", self._process.pid)
            self._process.terminate()
            try:
                self._process.wait(timeout=10)
            except subprocess.TimeoutExpired:
                self._process.kill()


if __name__ == "__main__":
    monitor = WatchdogMonitor()
    try:
        monitor.run()
    except KeyboardInterrupt:
        log.info("Watchdog stopped by user.")
        monitor.stop()
